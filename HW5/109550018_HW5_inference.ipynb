{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1573,"status":"ok","timestamp":1671541567075,"user":{"displayName":"郭昀","userId":"14595667254058274582"},"user_tz":-480},"id":"OSuHiNjMX26D"},"outputs":[],"source":["# import libaraies\n","import csv\n","import numpy as np\n","import random\n","import time\n","import os\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as F\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1671541586888,"user":{"displayName":"郭昀","userId":"14595667254058274582"},"user_tz":-480},"id":"geT1bPycX26F"},"outputs":[],"source":["# path of dataset\n","TRAIN_PATH = \"/content/drive/MyDrive/ML/captcha-hacker/train\"\n","TEST_PATH = \"/content/drive/MyDrive/ML/captcha-hacker/test\"\n","\n","# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":919,"status":"ok","timestamp":1671541587799,"user":{"displayName":"郭昀","userId":"14595667254058274582"},"user_tz":-480},"id":"AufyH0FLX26G"},"outputs":[],"source":["# mapping for label's one-hot encoding \n","mapping = { 'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, \n","            'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '0': 26, \n","            '1': 27, '2': 28, '3': 29, '4': 30, '5': 31, '6': 32, '7': 33, '8': 34, '9': 35 }\n","\n","# dataset classes\n","class Task1Dataset(Dataset):\n","    def __init__(self, data, root, return_filename=False):\n","        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n","        self.return_filename = return_filename\n","        self.root = root\n","    \n","    def __getitem__(self, index):\n","        filename, label = self.data[index]\n","        img = read_image(f\"{self.root}/{filename}\")\n","        if self.return_filename:\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), filename\n","        else:\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), int(label)\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","class Task2Dataset(Dataset):\n","    def __init__(self, data, root, return_filename=False):\n","        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n","        self.return_filename = return_filename\n","        self.root = root\n","    \n","    def __getitem__(self, index):\n","        filename, label = self.data[index]\n","        img = read_image(f\"{self.root}/{filename}\")\n","        if self.return_filename:\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor((img) / 255), filename\n","        else:\n","            # one-hot encoding\n","            encoding_label = [0] * 72\n","            encoding_label[mapping[label[1]] + 36] = 1\n","            encoding_label[mapping[label[0]]] = 1\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), torch.FloatTensor(encoding_label)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","class Task3Dataset(Dataset):\n","    def __init__(self, data, root, return_filename=False):\n","        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n","        self.return_filename = return_filename\n","        self.root = root\n","    \n","    def __getitem__(self, index):\n","        filename, label = self.data[index]\n","        img = read_image(f\"{self.root}/{filename}\")\n","        if self.return_filename:\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), filename\n","        else:\n","            # one-hot encoding\n","            encoding_label = [0] * 144\n","            encoding_label[mapping[label[3]] + 108] = 1\n","            encoding_label[mapping[label[2]] + 72] = 1\n","            encoding_label[mapping[label[1]] + 36] = 1\n","            encoding_label[mapping[label[0]]] = 1\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), torch.FloatTensor(encoding_label)\n","\n","    def __len__(self):\n","        return len(self.data)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671541587800,"user":{"displayName":"郭昀","userId":"14595667254058274582"},"user_tz":-480},"id":"PELuDRRnX26H"},"outputs":[],"source":["# mapping one-hot encoding back to string\n","mapping2 = { 0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', \n","            15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '0', 27: '1', 28: '2', \n","            29: '3', 30: '4', 31: '5', 32: '6', 33: '7', 34: '8', 35: '9'}\n","\n","def test(TASK, PATH, BATCH_SIZE, out_features):\n","    # select preprocess\n","    if TASK == \"task1\":\n","      preprocess = transforms.Compose([transforms.Resize((288, 288)), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","    elif TASK == \"task2\":\n","      preprocess = transforms.Compose([transforms.Resize((288, 288)), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","    else:\n","      preprocess = transforms.Compose([transforms.Resize((384, 288)), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","    # load test data\n","    test_data = []\n","    with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n","        for row in csv.reader(csvfile, delimiter=','):\n","            if row[0].startswith(TASK):\n","                test_data.append(row)\n","\n","    if TASK == \"task1\":\n","      test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\n","    elif TASK == \"task2\":\n","      test_ds = Task2Dataset(test_data, root=TEST_PATH, return_filename=True)\n","    else:\n","      test_ds = Task3Dataset(test_data, root=TEST_PATH, return_filename=True)\n","      \n","    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, drop_last=False, shuffle=False)\n","\n","    # open submission.csv for writing predictions\n","    if os.path.exists('submission.csv'):\n","        file = open('submission.csv', 'a', newline='')\n","        csv_writer = csv.writer(file)\n","    else:\n","        file = open('submission.csv', 'w', newline='')\n","        csv_writer = csv.writer(file)\n","        csv_writer.writerow([\"filename\", \"label\"])\n","\n","    # define model and load weights\n","    model = torchvision.models.resnet18()\n","    model.fc = nn.Linear(in_features=512, out_features=out_features, bias=True)\n","    model.load_state_dict(torch.load(PATH))\n","    model = model.to(device)\n","    \n","    # testing loop\n","    model.eval()\n","    with torch.no_grad():\n","        for image, filenames in test_dl:\n","            image = preprocess(image)\n","            image = image.to(device)\n","\n","            pred = model(image)\n","            temp = None\n","            if TASK == \"task1\":\n","                pred = torch.argmax(pred, dim=1)\n","                for i in range(len(filenames)):\n","                    csv_writer.writerow([filenames[i], str(pred[i].item())])\n","            elif TASK == \"task2\":\n","                pred = torch.softmax(pred, dim=1)\n","                pred = pred.view(-1, 2, 36)\n","                pred = torch.argmax(pred, dim=2)\n","                for i in range(len(filenames)):\n","                    temp = mapping2[pred[i][0].item()] + mapping2[pred[i][1].item()]\n","                    csv_writer.writerow([filenames[i], temp])\n","            else:\n","                pred = torch.softmax(pred, dim=1)\n","                pred = pred.view(-1, 4, 36)\n","                pred = torch.argmax(pred, dim=2)\n","                for i in range(len(filenames)):\n","                    temp = mapping2[pred[i][0].item()] + mapping2[pred[i][1].item()] + mapping2[pred[i][2].item()] + mapping2[pred[i][3].item()]\n","                    csv_writer.writerow([filenames[i], temp])\n","               \n","            # delete variable to avoid excess cuda memory\n","            del image, pred, temp\n","\n","    file.close()\n","    \n","    print(\"Finish\", TASK, \"!!\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5327624,"status":"ok","timestamp":1671546915420,"user":{"displayName":"郭昀","userId":"14595667254058274582"},"user_tz":-480},"id":"YGGmOXphX26I","outputId":"a505accf-0516-422d-8e65-78036d7fadcf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Finish task1 !!\n","Finish task2 !!\n","Finish task3 !!\n"]}],"source":["test(\"task1\", \"/content/drive/MyDrive/ML/task1_weight.pth\", 100, 10)\n","test(\"task2\", \"/content/drive/MyDrive/ML/task2_weight.pth\", 100, 36 + 36)\n","test(\"task3\", \"/content/drive/MyDrive/ML/task3_weight.pth\", 50, 36 + 36 + 36 + 36)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10 | packaged by conda-forge | (main, Feb  1 2022, 21:28:27) \n[Clang 11.1.0 ]"},"vscode":{"interpreter":{"hash":"e3ae70e51d0a81f5a9ce9a5aa0bda06ada15e9af7deae70d5f488fbd6e54dce1"}}},"nbformat":4,"nbformat_minor":0}
