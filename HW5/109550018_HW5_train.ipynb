{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:26:16.656166Z","iopub.status.busy":"2022-12-15T15:26:16.655717Z","iopub.status.idle":"2022-12-15T15:26:18.682622Z","shell.execute_reply":"2022-12-15T15:26:18.681663Z","shell.execute_reply.started":"2022-12-15T15:26:16.656080Z"},"papermill":{"duration":2.109989,"end_time":"2022-11-25T04:50:32.986527","exception":false,"start_time":"2022-11-25T04:50:30.876538","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# import libaraies\n","import csv\n","import numpy as np\n","import random\n","import time\n","import os\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as F\n","from torchvision.io import read_image\n","from torch.utils.data import DataLoader\n","import torch.optim as optim"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:26:18.684790Z","iopub.status.busy":"2022-12-15T15:26:18.684293Z","iopub.status.idle":"2022-12-15T15:26:18.695110Z","shell.execute_reply":"2022-12-15T15:26:18.693925Z","shell.execute_reply.started":"2022-12-15T15:26:18.684761Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'1.13.0'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["torch.__version__"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:26:18.697675Z","iopub.status.busy":"2022-12-15T15:26:18.696915Z","iopub.status.idle":"2022-12-15T15:26:18.766045Z","shell.execute_reply":"2022-12-15T15:26:18.765004Z","shell.execute_reply.started":"2022-12-15T15:26:18.697620Z"},"papermill":{"duration":0.014176,"end_time":"2022-11-25T04:50:33.004252","exception":false,"start_time":"2022-11-25T04:50:32.990076","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# path of dataset\n","TRAIN_PATH = \"/kaggle/input/captcha-hacker/train\"\n","TEST_PATH = \"/kaggle/input/captcha-hacker/test\"\n","\n","# Device configuration\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:26:18.771178Z","iopub.status.busy":"2022-12-15T15:26:18.770513Z","iopub.status.idle":"2022-12-15T15:26:18.788882Z","shell.execute_reply":"2022-12-15T15:26:18.787954Z","shell.execute_reply.started":"2022-12-15T15:26:18.771141Z"},"papermill":{"duration":0.017781,"end_time":"2022-11-25T04:50:33.025650","exception":false,"start_time":"2022-11-25T04:50:33.007869","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# mapping for label's one-hot encoding \n","mapping = { 'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, \n","            'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, '0': 26, \n","            '1': 27, '2': 28, '3': 29, '4': 30, '5': 31, '6': 32, '7': 33, '8': 34, '9': 35 }\n","\n","# dataset classes\n","class Task1Dataset(Dataset):\n","    def __init__(self, data, root, return_filename=False):\n","        self.data = [sample for sample in data if sample[0].startswith(TASK)]\n","        self.return_filename = return_filename\n","        self.root = root\n","    \n","    def __getitem__(self, index):\n","        filename, label = self.data[index]\n","        img = read_image(f\"{self.root}/{filename}\")\n","        if self.return_filename:\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), filename\n","        else:\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), int(label)\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","class Task2Dataset(Dataset):\n","    def __init__(self, data, root, return_filename=False):\n","        self.data = [sample for sample in data if sample[0].startswith(TASK)]\n","        self.return_filename = return_filename\n","        self.root = root\n","    \n","    def __getitem__(self, index):\n","        filename, label = self.data[index]\n","        img = read_image(f\"{self.root}/{filename}\")\n","        if self.return_filename:\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor((img) / 255), filename\n","        else:\n","            # one-hot encoding\n","            encoding_label = [0] * 72\n","            encoding_label[mapping[label[1]] + 36] = 1\n","            encoding_label[mapping[label[0]]] = 1\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), torch.FloatTensor(encoding_label)\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","class Task3Dataset(Dataset):\n","    def __init__(self, data, root, return_filename=False):\n","        self.data = [sample for sample in data if sample[0].startswith(TASK)]\n","        self.return_filename = return_filename\n","        self.root = root\n","    \n","    def __getitem__(self, index):\n","        filename, label = self.data[index]\n","        img = read_image(f\"{self.root}/{filename}\")\n","        if self.return_filename:\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), filename\n","        else:\n","            # one-hot encoding\n","            encoding_label = [0] * 144\n","            encoding_label[mapping[label[3]] + 108] = 1\n","            encoding_label[mapping[label[2]] + 72] = 1\n","            encoding_label[mapping[label[1]] + 36] = 1\n","            encoding_label[mapping[label[0]]] = 1\n","            # normalize the value of image to 0 ~ 1\n","            return torch.FloatTensor(img / 255), torch.FloatTensor(encoding_label)\n","\n","    def __len__(self):\n","        return len(self.data)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:26:18.791388Z","iopub.status.busy":"2022-12-15T15:26:18.790641Z","iopub.status.idle":"2022-12-15T15:26:18.801549Z","shell.execute_reply":"2022-12-15T15:26:18.800599Z","shell.execute_reply.started":"2022-12-15T15:26:18.791353Z"},"papermill":{"duration":0.035192,"end_time":"2022-11-25T04:50:33.081577","exception":false,"start_time":"2022-11-25T04:50:33.046385","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# get train data and validation data\n","def get_dataLoader(TASK):  \n","    random.seed(time.time())\n","    train_data = []\n","    val_data = []\n","\n","    with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n","        for row in csv.reader(csvfile, delimiter=','):\n","            if row[0].startswith(TASK):\n","                # random distribute data to train set or validation set\n","                if random.random() < 0.9:\n","                    train_data.append(row)\n","                else:\n","                    val_data.append(row)\n","    \n","    if TASK == \"task1\":\n","        train_ds = Task1Dataset(train_data, root=TRAIN_PATH)\n","        val_ds = Task1Dataset(val_data, root=TRAIN_PATH)\n","    elif TASK == \"task2\":\n","        train_ds = Task2Dataset(train_data, root=TRAIN_PATH)\n","        val_ds = Task2Dataset(val_data, root=TRAIN_PATH)\n","    else:\n","        train_ds = Task3Dataset(train_data, root=TRAIN_PATH)\n","        val_ds = Task3Dataset(val_data, root=TRAIN_PATH)\n","\n","    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, drop_last=True, shuffle=True)\n","    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, drop_last=False, shuffle=False)\n","    \n","    return train_dl, val_dl"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:26:18.803535Z","iopub.status.busy":"2022-12-15T15:26:18.803132Z","iopub.status.idle":"2022-12-15T15:26:18.819403Z","shell.execute_reply":"2022-12-15T15:26:18.818524Z","shell.execute_reply.started":"2022-12-15T15:26:18.803500Z"},"trusted":true},"outputs":[],"source":["def train(model, preprocess, optimizer, loss_fn, train_dl, TASK, PATH):\n","    # training loop\n","    for epoch in range(NUM_EPOCHS):\n","        print(f\"Epoch [{epoch}]\", end=\" -> \")\n","        model.train()\n","        for image, label in train_dl:\n","            image = preprocess(image)\n","            image = image.to(device)\n","            label = label.to(device)\n","\n","            pred = model(image)\n","            loss = loss_fn(pred, label)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        sample_count = 0\n","        correct_count = 0\n","\n","        # evaluate the traning with validation data\n","        model.eval()\n","        with torch.no_grad():\n","            for image, label in val_dl:\n","                image = preprocess(image)\n","                image = image.to(device)\n","                label = label.to(device)\n","\n","                pred = model(image)\n","                loss = loss_fn(pred, label)\n","                \n","                if TASK == \"task1\":                    # pred is a number\n","                    pred = torch.argmax(pred, dim=1)\n","                    sample_count += len(image)\n","                    correct_count += (label == pred).sum()\n","                elif TASK == \"task2\":                  # pred is one-hot encoding vector\n","                    pred = torch.softmax(pred, dim=1)\n","                    pred = pred.view(-1, 2, 36)\n","                    pred = torch.argmax(pred, dim=2)\n","                    label = label.view(-1, 2, 36)\n","                    label = torch.argmax(label, dim=2)\n","                    sample_count += len(image)\n","                    for i in range(len(pred)):\n","                        if pred[i][0] == label[i][0] and pred[i][1] == label[i][1]:\n","                            correct_count += 1\n","                else:                                  # pred is one-hot encoding vector\n","                    pred = torch.softmax(pred, dim=1)\n","                    pred = pred.view(-1, 4, 36)\n","                    pred = torch.argmax(pred, dim=2)\n","                    label = label.view(-1, 4, 36)\n","                    label = torch.argmax(label, dim=2)\n","                    sample_count += len(image)\n","                    for i in range(len(pred)):\n","                        if pred[i][0] == label[i][0] and pred[i][1] == label[i][1] and pred[i][2] == label[i][2] and pred[i][3] == label[i][3]:\n","                            correct_count += 1\n","                            \n","                # delete variable to avoid excess cuda memory\n","                del image, label, pred\n","\n","        print(\"accuracy (validation):\", (correct_count / sample_count))\n","\n","    # save model weight\n","    torch.save(model.state_dict(), PATH)\n","    \n","    print(\"Finish Training !!\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:26:18.821393Z","iopub.status.busy":"2022-12-15T15:26:18.820993Z","iopub.status.idle":"2022-12-15T15:26:18.840020Z","shell.execute_reply":"2022-12-15T15:26:18.838976Z","shell.execute_reply.started":"2022-12-15T15:26:18.821355Z"},"trusted":true},"outputs":[],"source":["# mapping one-hot encoding back to string\n","mapping2 = { 0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', \n","            15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z', 26: '0', 27: '1', 28: '2', \n","            29: '3', 30: '4', 31: '5', 32: '6', 33: '7', 34: '8', 35: '9'}\n","    \n","\n","def test(PATH, out_features, TASK):\n","    # load test data\n","    test_data = []\n","    with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:\n","        for row in csv.reader(csvfile, delimiter=','):\n","            if row[0].startswith(TASK):\n","                test_data.append(row)\n","\n","    test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)\n","    test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, drop_last=False, shuffle=False)\n","\n","    # open submission.csv for writing predictions\n","    if os.path.exists('submission.csv'):\n","        file = open('submission.csv', 'a', newline='')\n","        csv_writer = csv.writer(file)\n","    else:\n","        file = open('submission.csv', 'w', newline='')\n","        csv_writer = csv.writer(file)\n","        csv_writer.writerow([\"filename\", \"label\"])\n","\n","    model = torchvision.models.resnet18()\n","    model.fc = nn.Linear(in_features=512, out_features=out_features, bias=True)\n","    model.load_state_dict(torch.load(PATH))\n","    model = model.to(device)\n","    \n","    # testing loop\n","    model.eval()\n","    with torch.no_grad():\n","        for image, filenames in test_dl:\n","            image = preprocess(image)\n","            image = image.to(device)\n","\n","            pred = model(image)\n","            temp = None\n","            if TASK == \"task1\":\n","                pred = torch.argmax(pred, dim=1)\n","                for i in range(len(filenames)):\n","                    csv_writer.writerow([filenames[i], str(pred[i].item())])\n","            elif TASK == \"task2\":\n","                pred = torch.softmax(pred, dim=1)\n","                pred = pred.view(-1, 2, 36)\n","                pred = torch.argmax(pred, dim=2)\n","                for i in range(len(filenames)):\n","                    temp = mapping2[pred[i][0].item()] + mapping2[pred[i][1].item()]\n","                    csv_writer.writerow([filenames[i], temp])\n","            else:\n","                pred = torch.softmax(pred, dim=1)\n","                pred = pred.view(-1, 4, 36)\n","                pred = torch.argmax(pred, dim=2)\n","                for i in range(len(filenames)):\n","                    temp = mapping2[pred[i][0].item()] + mapping2[pred[i][1].item()] + mapping2[pred[i][2].item()] + mapping2[pred[i][3].item()]\n","                    csv_writer.writerow([filenames[i], temp])\n","               \n","            # delete variable to avoid excess cuda memory\n","            del image, pred, temp\n","\n","    file.close()\n","    \n","    print(\"Finish\", TASK, \"!!\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 1"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:26:18.841999Z","iopub.status.busy":"2022-12-15T15:26:18.841555Z","iopub.status.idle":"2022-12-15T15:28:49.968755Z","shell.execute_reply":"2022-12-15T15:28:49.967650Z","shell.execute_reply.started":"2022-12-15T15:26:18.841965Z"},"papermill":{"duration":215.563244,"end_time":"2022-11-25T04:54:08.648449","exception":false,"start_time":"2022-11-25T04:50:33.085205","status":"completed"},"tags":[],"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/captcha-hacker/train/annotations.csv'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/guoyun/Desktop/機器學習/CS_CS20024/HW5/109550018-hw5-train.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtask1_weight.pth\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m out_features \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m train_dl, val_dl \u001b[39m=\u001b[39m get_dataLoader(TASK)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# define model using resnet18 with pretrained weight\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m task1Model \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mresnet18(pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[1;32m/Users/guoyun/Desktop/機器學習/CS_CS20024/HW5/109550018-hw5-train.ipynb Cell 9\u001b[0m in \u001b[0;36mget_dataLoader\u001b[0;34m(TASK)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_data \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m val_data \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mTRAIN_PATH\u001b[39m}\u001b[39;49;00m\u001b[39m/annotations.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, newline\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m csvfile:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m csv\u001b[39m.\u001b[39mreader(csvfile, delimiter\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39mif\u001b[39;00m row[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstartswith(TASK):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guoyun/Desktop/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/CS_CS20024/HW5/109550018-hw5-train.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             \u001b[39m# random distribute data to train set or validation set\u001b[39;00m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/captcha-hacker/train/annotations.csv'"]}],"source":["# define hyperparameters for task 1\n","TASK = \"task1\"\n","BATCH_SIZE = 100\n","NUM_EPOCHS = 10\n","LR = 1e-3\n","PATH = \"task1_weight.pth\"\n","out_features = 10\n","\n","train_dl, val_dl = get_dataLoader(TASK)\n","\n","# define model using resnet18 with pretrained weight\n","task1Model = torchvision.models.resnet18(pretrained=True)\n","task1Model.fc = nn.Linear(in_features=512, out_features=out_features, bias=True)\n","task1Model = task1Model.to(device)\n","\n","# define Adam as optimizer and CrossEntropyLoss as loss function\n","optimizer = torch.optim.Adam(task1Model.parameters(), lr=LR)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","# define transforms for data preprocessing\n","preprocess = transforms.Compose([transforms.Resize((288, 288)), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","train(task1Model, preprocess, optimizer, loss_fn, train_dl, TASK, PATH)\n","# test(PATH, out_features, TASK)"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:28:49.971920Z","iopub.status.busy":"2022-12-15T15:28:49.970277Z","iopub.status.idle":"2022-12-15T15:30:41.042755Z","shell.execute_reply":"2022-12-15T15:30:41.041635Z","shell.execute_reply.started":"2022-12-15T15:28:49.971880Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0] -> accuracy (validation): 0.072\n","Epoch [1] -> accuracy (validation): 0.648\n","Epoch [2] -> accuracy (validation): 0.98\n","Epoch [3] -> accuracy (validation): 0.988\n","Epoch [4] -> accuracy (validation): 0.996\n","Epoch [5] -> accuracy (validation): 0.996\n","Epoch [6] -> accuracy (validation): 1.0\n","Epoch [7] -> accuracy (validation): 1.0\n","Epoch [8] -> accuracy (validation): 1.0\n","Epoch [9] -> accuracy (validation): 1.0\n","Finish Training !!\n","Finish Testing !!\n"]}],"source":["# define hyperparameters for task 2\n","TASK = \"task2\"\n","BATCH_SIZE = 100\n","NUM_EPOCHS = 10\n","LR = 1e-3\n","PATH = \"task2_weight.pth\"\n","out_features = 36 + 36\n","\n","train_dl, val_dl = get_dataLoader(TASK)\n","\n","# define model using resnet18 with pretrained weight\n","task2Model = torchvision.models.resnet18(pretrained=True)\n","task2Model.fc = nn.Linear(in_features=512, out_features=out_features, bias=True)\n","task2Model = task2Model.to(device)\n","\n","# define Adam as optimizer and MultiLabelSoftMarginLoss as loss function\n","optimizer = torch.optim.Adam(task2Model.parameters(), lr=LR)\n","loss_fn = nn.MultiLabelSoftMarginLoss()\n","\n","# define transforms for data preprocessing\n","preprocess = transforms.Compose([transforms.Resize((288, 288)), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","train(task2Model, preprocess, optimizer, loss_fn, train_dl, TASK, PATH)\n","# test(PATH, out_features, TASK)"]},{"cell_type":"markdown","metadata":{},"source":["#### Task 3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-12-15T15:30:41.046507Z","iopub.status.busy":"2022-12-15T15:30:41.045869Z","iopub.status.idle":"2022-12-15T15:34:32.528352Z","shell.execute_reply":"2022-12-15T15:34:32.527155Z","shell.execute_reply.started":"2022-12-15T15:30:41.046469Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [0] -> accuracy (validation): 0.0\n","Epoch [1] -> accuracy (validation): 0.0\n","Epoch [2] -> accuracy (validation): 0.1258741258741259\n","Epoch [3] -> accuracy (validation): 0.548951048951049\n","Epoch [4] -> accuracy (validation): 0.7692307692307693\n","Epoch [5] -> accuracy (validation): 0.8881118881118881\n","Epoch [6] -> accuracy (validation): 0.9055944055944056\n","Epoch [7] -> accuracy (validation): 0.9440559440559441\n","Epoch [8] -> accuracy (validation): 0.9440559440559441\n","Epoch [9] -> accuracy (validation): 0.965034965034965\n","Epoch [10] -> accuracy (validation): 0.958041958041958\n","Epoch [11] -> accuracy (validation): 0.9755244755244755\n","Epoch [12] -> accuracy (validation): 0.9825174825174825\n","Epoch [13] -> accuracy (validation): 0.9790209790209791\n","Epoch [14] -> accuracy (validation): 0.965034965034965\n","Finish Training !!\n","Finish Testing !!\n"]}],"source":["# define hyperparameters for task 3\n","TASK = \"task3\"\n","BATCH_SIZE = 50\n","NUM_EPOCHS = 15\n","LR = 1e-3\n","PATH = \"task3_weight.pth\"\n","out_features = 36 + 36 + 36 + 36\n","\n","train_dl, val_dl = get_dataLoader(TASK)\n","\n","# define model using resnet18 with pretrained weight\n","task3Model = torchvision.models.resnet18(pretrained=True)\n","task3Model.fc = nn.Linear(in_features=512, out_features=out_features, bias=True)\n","task3Model = task3Model.to(device)\n","\n","# define Adam as optimizer and MultiLabelSoftMarginLoss as loss function\n","optimizer = torch.optim.Adam(task3Model.parameters(), lr=LR)\n","loss_fn = nn.MultiLabelSoftMarginLoss()\n","\n","# define transforms for data preprocessing\n","preprocess = transforms.Compose([transforms.Resize((384, 288)), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","\n","train(task3Model, preprocess, optimizer, loss_fn, train_dl, TASK, PATH)\n","# test(PATH, out_features, TASK)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"papermill":{"default_parameters":{},"duration":242.076508,"end_time":"2022-11-25T04:54:16.697471","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-11-25T04:50:14.620963","version":"2.3.4"},"vscode":{"interpreter":{"hash":"e3ae70e51d0a81f5a9ce9a5aa0bda06ada15e9af7deae70d5f488fbd6e54dce1"}}},"nbformat":4,"nbformat_minor":5}
